import streamlit as st
import pandas as pd
import joblib
import os, sys
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc

# ensure repo root in sys.path
REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if REPO_ROOT not in sys.path:
    sys.path.insert(0, REPO_ROOT)

from src.preprocessing import clean_text

st.set_page_config(page_title='åƒåœ¾ç°¡è¨Šåˆ†é¡ç³»çµ±', page_icon='ğŸ“§', layout='centered')

st.markdown("""<h1 style='text-align:center;color:#22577A;'>ğŸ“§ åƒåœ¾ç°¡è¨Šåˆ†é¡ç³»çµ±ï¼ˆè‡ªè¨‚æ¨¡å‹ï¼‰</h1>""", unsafe_allow_html=True)

with st.sidebar:
    st.header('âš™ï¸ æ¨¡å‹è¨­å®š (ä½¿ç”¨ä½¿ç”¨è€…æ¨¡å‹æª”æ¡ˆ)')
    st.write('æœŸæœ›æª”åï¼š')
    st.code('spam_logreg_model.joblib\nspam_tfidf_vectorizer.joblib\nspam_label_mapping.json')
    st.caption('è‹¥ä½ æœ‰è‡ªå·±çš„æ¨¡å‹æª”ï¼Œè«‹æ”¾åˆ° /models ä¸¦ä½¿ç”¨ç›¸åŒæª”åã€‚')

# model files
model_file = os.path.join('models','spam_logreg_model.joblib')
vec_file = os.path.join('models','spam_tfidf_vectorizer.joblib')
map_file = os.path.join('models','spam_label_mapping.json')

if not os.path.exists(model_file) or not os.path.exists(vec_file):
    st.error('æ‰¾ä¸åˆ°æ¨¡å‹æˆ–å‘é‡å™¨ã€‚è«‹å°‡ spam_logreg_model.joblib èˆ‡ spam_tfidf_vectorizer.joblib æ”¾å…¥ models/ è³‡æ–™å¤¾ã€‚')
    st.stop()

model = joblib.load(model_file)
vectorizer = joblib.load(vec_file)

st.subheader('ğŸ” å–®ç­†é æ¸¬')
txt = st.text_area('è¼¸å…¥ç°¡è¨Šå…§å®¹', height=120)
if st.button('é æ¸¬'):
    if txt.strip()=='':
        st.warning('è«‹è¼¸å…¥æ–‡å­—')
    else:
        t = clean_text(txt)
        x = vectorizer.transform([t])
        pred = model.predict(x)[0]
        if hasattr(model,'predict_proba'):
            prob = model.predict_proba(x)[0][1]
            st.info(f'åƒåœ¾è¨Šæ¯æ©Ÿç‡: {prob:.4f}')
        st.write('çµæœ:', 'SPAM' if pred==1 else 'HAM')

st.markdown('---')
st.subheader('ğŸ“‚ æ‰¹æ¬¡é æ¸¬ (CSV)')
uploaded = st.file_uploader('ä¸Šå‚³ CSVï¼ˆéœ€å« text æ¬„ä½ï¼‰', type=['csv'])
if uploaded:
    df = pd.read_csv(uploaded)
    if 'text' not in df.columns:
        st.error('CSV å¿…é ˆå« text æ¬„ä½')
    else:
        df['text_clean'] = df['text'].astype(str).apply(clean_text)
        X = vectorizer.transform(df['text_clean'])
        df['pred'] = model.predict(X)
        if hasattr(model,'predict_proba'):
            df['spam_prob'] = model.predict_proba(X)[:,1]
        st.dataframe(df)
        st.download_button('ä¸‹è¼‰çµæœ', df.to_csv(index=False).encode('utf-8-sig'), 'predictions.csv')

# evaluation if dataset present
ds = os.path.join('Chapter03','datasets','sms_spam_no_header.csv')
if os.path.exists(ds):
    df_all = pd.read_csv(ds, header=None, names=['label','text'])
    df_all['label'] = df_all['label'].map({'ham':0,'spam':1})
    df_all['text_clean'] = df_all['text'].astype(str).apply(clean_text)
    X_all = vectorizer.transform(df_all['text_clean'])
    preds = model.predict(X_all)
    st.subheader('ğŸ“Š åˆ†é¡å ±å‘Š')
    st.text(classification_report(df_all['label'], preds, target_names=['HAM','SPAM']))
    cm = confusion_matrix(df_all['label'], preds)
    fig,ax = plt.subplots(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
    st.pyplot(fig)
else:
    st.info('è³‡æ–™é›†ç¼ºå¤±ï¼šè«‹æ”¾ Chapter03/datasets/sms_spam_no_header.csv')
